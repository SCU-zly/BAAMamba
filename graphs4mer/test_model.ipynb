{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prune_method = 'thresh_abs'\n",
    "edge_top_perc = 0.2\n",
    "K = 3\n",
    "thresh = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.graph_learner import *\n",
    "hidden_dim = 384\n",
    "num_nodes = 4\n",
    "embed_dim = 16\n",
    "num_dynamic_graphs = 2\n",
    "resolution = 98\n",
    "#TODO: add support for those two parameters\n",
    "undirected_graph = True\n",
    "regularizations = [\"feature_smoothing\", \"degree\", \"sparse\"]\n",
    "attn_layers = GraphLearner(\n",
    "            input_size=hidden_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_nodes=num_nodes,\n",
    "            embed_dim=embed_dim,\n",
    "            metric_type=\"self_attention\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_knn_graph(x, k, dist_measure=\"cosine\", undirected=undirected_graph):\n",
    "\n",
    "    if dist_measure == \"euclidean\":\n",
    "        dist = torch.cdist(x, x, p=2.0)\n",
    "        dist = (dist - dist.min()) / (dist.max() - dist.min())\n",
    "        knn_val, knn_ind = torch.topk(\n",
    "            dist, k, dim=-1, largest=False\n",
    "        )  # smallest distances\n",
    "    elif dist_measure == \"cosine\":\n",
    "        norm = torch.norm(x, dim=-1, p=\"fro\")[:, :, None]\n",
    "        x_norm = x / norm\n",
    "        dist = torch.matmul(x_norm, x_norm.transpose(1, 2))\n",
    "        knn_val, knn_ind = torch.topk(\n",
    "            dist, k, dim=-1, largest=True\n",
    "        )  # largest similarities\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    adj_mat = (torch.ones_like(dist) * 0).scatter_(-1, knn_ind, knn_val).to(x.device)\n",
    "\n",
    "    adj_mat = torch.clamp(adj_mat, min=0.0)  # remove negatives\n",
    "\n",
    "    if undirected:\n",
    "        adj_mat = (adj_mat + adj_mat.transpose(1, 2)) / 2\n",
    "\n",
    "    # add self-loop\n",
    "    I = (\n",
    "        torch.eye(adj_mat.shape[-1], adj_mat.shape[-1])\n",
    "        .unsqueeze(0)\n",
    "        .repeat(adj_mat.shape[0], 1, 1)\n",
    "        .to(bool)\n",
    "    ).to(x.device)\n",
    "    adj_mat = adj_mat * (~I) + I\n",
    "\n",
    "    # to sparse graph\n",
    "    edge_index, edge_weight = torch_geometric.utils.dense_to_sparse(adj_mat)\n",
    "\n",
    "    return edge_index, edge_weight, adj_mat\n",
    "\n",
    "def prune_adj_mat(adj_mat, num_nodes, method=\"thresh\", edge_top_perc=None, knn=None, thresh=None):\n",
    "    \n",
    "    if method == \"thresh\":\n",
    "        sorted, indices = torch.sort(\n",
    "            adj_mat.reshape(-1, num_nodes * num_nodes),\n",
    "            dim=-1,\n",
    "            descending=True,\n",
    "        )\n",
    "        K = int((num_nodes**2) * edge_top_perc)\n",
    "        mask = adj_mat > sorted[:, K].unsqueeze(1).unsqueeze(2)\n",
    "        adj_mat = adj_mat * mask\n",
    "    elif method == \"knn\":\n",
    "        knn_val, knn_ind = torch.topk(\n",
    "            adj_mat, knn, dim=-1, largest=True\n",
    "        )\n",
    "        adj_mat = (torch.ones_like(adj_mat) * 0).scatter_(-1, knn_ind, knn_val).to(adj_mat.device)\n",
    "    elif method == \"thresh_abs\":\n",
    "        mask = (adj_mat > thresh).float()\n",
    "        adj_mat = adj_mat * mask\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    return adj_mat\n",
    "\n",
    "def calculate_normalized_laplacian(adj):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        adj: torch tensor, shape (batch, num_nodes, num_nodes)\n",
    "\n",
    "    L = D^-1/2 (D-A) D^-1/2 = I - D^-1/2 A D^-1/2\n",
    "    D = diag(A)\n",
    "    \"\"\"\n",
    "\n",
    "    batch, num_nodes, _ = adj.shape\n",
    "    d = adj.sum(-1)  # (batch, num_nodes)\n",
    "    d_inv_sqrt = torch.pow(d, -0.5)\n",
    "    d_inv_sqrt[torch.isinf(d_inv_sqrt)] = 0.0\n",
    "    d_mat_inv_sqrt = torch.diag_embed(d_inv_sqrt)  # (batch, num_nodes, num_nodes)\n",
    "\n",
    "    identity = (torch.eye(num_nodes).unsqueeze(0).repeat(batch, 1, 1)).to(\n",
    "        adj.device\n",
    "    )  # (batch, num_nodes, num_nodes)\n",
    "    normalized_laplacian = identity - torch.matmul(\n",
    "        torch.matmul(d_mat_inv_sqrt, adj), d_mat_inv_sqrt\n",
    "    )\n",
    "\n",
    "def feature_smoothing(adj, X):\n",
    "\n",
    "    # normalized laplacian\n",
    "    L = calculate_normalized_laplacian(adj)\n",
    "\n",
    "    feature_dim = X.shape[-1]\n",
    "    mat = torch.matmul(torch.matmul(X.transpose(1, 2), L), X) / (feature_dim**2)\n",
    "    loss = mat.diagonal(offset=0, dim1=-1, dim2=-2).sum(-1)  # batched trace\n",
    "    return loss\n",
    "#TODO: add support for those two parameters\n",
    "def regularization_loss(x, adj, reduce=\"mean\"):\n",
    "    \"\"\"\n",
    "    Referred to https://github.com/hugochan/IDGL/blob/master/src/core/model_handler.py#L1116\n",
    "    \"\"\"\n",
    "    batch, num_nodes, _ = x.shape\n",
    "    n = num_nodes\n",
    "\n",
    "    loss = {}\n",
    "\n",
    "    if \"feature_smoothing\" in regularizations:\n",
    "        curr_loss = feature_smoothing(adj=adj, X=x) / (n**2)\n",
    "        if reduce == \"mean\":\n",
    "            loss[\"feature_smoothing\"] = torch.mean(curr_loss)\n",
    "        elif reduce == \"sum\":\n",
    "            loss[\"feature_smoothing\"] = torch.sum(curr_loss)\n",
    "        else:\n",
    "            loss[\"feature_smoothing\"] = curr_loss\n",
    "\n",
    "    if \"degree\" in regularizations:\n",
    "        ones = torch.ones(batch, num_nodes, 1).to(x.device)\n",
    "        curr_loss = -(1 / n) * torch.matmul(\n",
    "            ones.transpose(1, 2), torch.log(torch.matmul(adj, ones))\n",
    "        ).squeeze(-1).squeeze(-1)\n",
    "        if reduce == \"mean\":\n",
    "            loss[\"degree\"] = torch.mean(curr_loss)\n",
    "        elif reduce == \"sum\":\n",
    "            loss[\"degree\"] = torch.sum(curr_loss)\n",
    "        else:\n",
    "            loss[\"degree\"] = curr_loss\n",
    "\n",
    "    if \"sparse\" in regularizations:\n",
    "        curr_loss = (\n",
    "            1 / (n**2) * torch.pow(torch.norm(adj, p=\"fro\", dim=(-1, -2)), 2)\n",
    "        )\n",
    "\n",
    "        if reduce == \"mean\":\n",
    "            loss[\"sparse\"] = torch.mean(curr_loss)\n",
    "        elif reduce == \"sum\":\n",
    "            loss[\"sparse\"] = torch.sum(curr_loss)\n",
    "        else:\n",
    "            loss[\"sparse\"] = curr_loss\n",
    "\n",
    "    if \"symmetric\" in regularizations and undirected_graph:\n",
    "        curr_loss = torch.norm(adj - adj.transpose(1, 2), p=\"fro\", dim=(-1, -2))\n",
    "        if reduce == \"mean\":\n",
    "            loss[\"symmetric\"] = torch.mean(curr_loss)\n",
    "        elif reduce == \"sum\":\n",
    "            loss[\"symmetric\"] = torch.sum(curr_loss)\n",
    "        else:\n",
    "            loss[\"symmetric\"] = curr_loss\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.randn(32, 4, 196, 384)  # (batch_size, num_nodes, seq_len, hidden_dim)\n",
    "batch,num_nodes,seq_len,hidden_dim = inputs.size()\n",
    "#这一段是加入的\n",
    "x = inputs.permute(0,2,1,3).contiguous() #(batch, seq_len, num_nodes, hidden_dim)\n",
    "x_ = []\n",
    "for t in range(num_dynamic_graphs):\n",
    "    start = t * resolution\n",
    "    stop = start + resolution\n",
    "    curr_x = torch.mean(x[:, start:stop, :, :], dim=1)\n",
    "    x_.append(curr_x)\n",
    "x_ = torch.stack(\n",
    "    x_, dim=1\n",
    ")  # (batch, num_dynamic_graphs, num_nodes, hidden_dim)\n",
    "x = x_.reshape(\n",
    "    -1, num_nodes, hidden_dim\n",
    ")  # (batch * num_dynamic_graphs, num_nodes, hidden_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 4, 384])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index, edge_weight, adj_mat = get_knn_graph(\n",
    "    x,\n",
    "    K,\n",
    "    dist_measure=\"cosine\",\n",
    "    undirected=True,\n",
    ")\n",
    "# edge_index = edge_index.to(x.device)\n",
    "# edge_weight = edge_weight.to(x.device)\n",
    "# adj_mat = adj_mat.to(x.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 4, 384])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn adj mat\n",
    "attn_weight = attn_layers(\n",
    "    x\n",
    ")  # (batch*num_dynamic_graphs, num_nodes, num_nodes)\n",
    "\n",
    "# to undirected\n",
    "attn_weight = (attn_weight + attn_weight.transpose(1, 2)) / 2\n",
    "raw_attn_weight = attn_weight.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 4, 4])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add residual\n",
    "if len(adj_mat.shape) == 2:\n",
    "    adj_mat = torch.cat([adj_mat] * num_dynamic_graphs * batch, dim=0)\n",
    "elif len(adj_mat.shape) == 3 and (adj_mat.shape != attn_weight.shape):\n",
    "    adj_mat = torch.cat([adj_mat] * num_dynamic_graphs, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn graph weight (aka residual weight) decay\n",
    "# if self.decay_residual_weight:\n",
    "#     assert (epoch is not None) and (epoch_total is not None)\n",
    "#     residual_weight = calculate_cosine_decay_weight(\n",
    "#         max_weight=self.residual_weight, epoch=epoch, epoch_total=epoch_total, min_weight=0\n",
    "#     )\n",
    "# else:\n",
    "#     residual_weight = 0.6\n",
    "# add knn graph\n",
    "residual_weight = 0.6\n",
    "adj_mat = (\n",
    "    residual_weight * adj_mat + (1 - residual_weight) * attn_weight\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "matmul(): argument 'other' (position 2) must be Tensor, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 13\u001b[0m\n\u001b[0;32m      2\u001b[0m adj_mat \u001b[38;5;241m=\u001b[39m prune_adj_mat(\n\u001b[0;32m      3\u001b[0m     adj_mat,\n\u001b[0;32m      4\u001b[0m     num_nodes,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m     thresh\u001b[38;5;241m=\u001b[39mthresh,\n\u001b[0;32m      9\u001b[0m )\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# regularization loss\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m#TODO add support for those two parameters\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m reg_losses \u001b[38;5;241m=\u001b[39m \u001b[43mregularization_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madj_mat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# back to sparse graph\u001b[39;00m\n\u001b[0;32m     16\u001b[0m edge_index, edge_weight \u001b[38;5;241m=\u001b[39m torch_geometric\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdense_to_sparse(adj_mat)\n",
      "Cell \u001b[1;32mIn[4], line 105\u001b[0m, in \u001b[0;36mregularization_loss\u001b[1;34m(x, adj, reduce)\u001b[0m\n\u001b[0;32m    102\u001b[0m loss \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature_smoothing\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m regularizations:\n\u001b[1;32m--> 105\u001b[0m     curr_loss \u001b[38;5;241m=\u001b[39m \u001b[43mfeature_smoothing\u001b[49m\u001b[43m(\u001b[49m\u001b[43madj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m (n\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m reduce \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    107\u001b[0m         loss[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature_smoothing\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(curr_loss)\n",
      "Cell \u001b[1;32mIn[4], line 91\u001b[0m, in \u001b[0;36mfeature_smoothing\u001b[1;34m(adj, X)\u001b[0m\n\u001b[0;32m     88\u001b[0m L \u001b[38;5;241m=\u001b[39m calculate_normalized_laplacian(adj)\n\u001b[0;32m     90\u001b[0m feature_dim \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m---> 91\u001b[0m mat \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mL\u001b[49m\u001b[43m)\u001b[49m, X) \u001b[38;5;241m/\u001b[39m (feature_dim\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     92\u001b[0m loss \u001b[38;5;241m=\u001b[39m mat\u001b[38;5;241m.\u001b[39mdiagonal(offset\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, dim1\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, dim2\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# batched trace\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[1;31mTypeError\u001b[0m: matmul(): argument 'other' (position 2) must be Tensor, not NoneType"
     ]
    }
   ],
   "source": [
    "# prune graph\n",
    "adj_mat = prune_adj_mat(\n",
    "    adj_mat,\n",
    "    num_nodes,\n",
    "    method=prune_method,\n",
    "    edge_top_perc=edge_top_perc,\n",
    "    knn=K,\n",
    "    thresh=thresh,\n",
    ")\n",
    "\n",
    "# regularization loss\n",
    "#TODO add support for those two parameters\n",
    "reg_losses = regularization_loss(x, adj=adj_mat)\n",
    "\n",
    "# back to sparse graph\n",
    "edge_index, edge_weight = torch_geometric.utils.dense_to_sparse(adj_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add self-loop\n",
    "edge_index, edge_weight = torch_geometric.utils.remove_self_loops(\n",
    "    edge_index=edge_index, edge_attr=edge_weight\n",
    ")\n",
    "edge_index, edge_weight = torch_geometric.utils.add_self_loops(\n",
    "    edge_index=edge_index,\n",
    "    edge_attr=edge_weight,\n",
    "    fill_value=1,\n",
    ")\n",
    "\n",
    "x = x.view(\n",
    "    batch * num_dynamic_graphs * num_nodes, -1\n",
    ")  # (batch * num_dynamic_graphs * num_nodes, hidden_dim)\n",
    "for i in range(len(self.gnn_layers)):\n",
    "    # gnn layer\n",
    "    x = self.gnn_layers[i](\n",
    "        x, edge_index=edge_index, edge_attr=edge_weight.reshape(-1, 1)\n",
    "    )\n",
    "    x = self.dropout(\n",
    "        self.activation(x)\n",
    "    )  # (batch * num_dynamic_graphs * num_nodes, hidden_dim)\n",
    "x = x.view(batch * num_dynamic_graphs, num_nodes, -1).view(\n",
    "    batch, num_dynamic_graphs, num_nodes, -1\n",
    ")  \n",
    " # (batch, num_dynamic_graphs, num_nodes, hidden_dim)\n",
    "\n",
    "# temporal pool\n",
    "if self.temporal_pool == \"last\":\n",
    "    x = x[:, -1, :, :]  # (batch, num_nodes, hidden_dim)\n",
    "elif self.temporal_pool == \"mean\":\n",
    "    x = torch.mean(x, dim=1)\n",
    "else:\n",
    "    raise NotImplementedError\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zlylab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
